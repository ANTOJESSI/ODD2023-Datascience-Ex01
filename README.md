# Ex-01_DS_Data_Cleansing


## AIM
To read the given data and perform data cleaning and save the cleaned data to a file. 

# Explanation
Data cleaning is the process of preparing data for analysis by removing or modifying data that is incorrect ,incompleted , irrelevant , duplicated or improperly formatted. 
Data cleaning is not simply about erasing data ,but rather finding a way to maximize datasets accuracy without necessarily deleting the information. 

# ALGORITHM
### STEP 1
Read the given Data
### STEP 2
Get the information about the data
### STEP 3
Remove the null values from the data
### STEP 4
Save the Clean data to the file

# CODE and OUTPUT
![Screenshot 2024-08-20 111936](https://github.com/user-attachments/assets/81169d4c-5e6e-44b3-8cb2-09e34572fb44)
![Screenshot 2024-08-20 112143](https://github.com/user-attachments/assets/ca80b9b7-784a-467b-b3f8-d7fff1ffa89e)
![Screenshot 2024-08-20 112201](https://github.com/user-attachments/assets/91f0e61a-b056-4fd1-9289-32c037890c3d)
![Screenshot 2024-08-20 112213](https://github.com/user-attachments/assets/a7649241-5483-42c3-a89d-c4b8be4a18f3)
![Screenshot 2024-08-20 112222](https://github.com/user-attachments/assets/8ac7d7e6-de7c-470f-97a0-1e01a4f89242)
![Screenshot 2024-08-20 112234](https://github.com/user-attachments/assets/957ba908-c9f5-40a1-a3c6-22bd4cc035fd)
![Screenshot 2024-08-20 112247](https://github.com/user-attachments/assets/67727e64-724c-401e-91c2-f6ad70626f63)
![Screenshot 2024-08-20 112300](https://github.com/user-attachments/assets/83021436-c3fa-4707-92e3-11178f250443)
![Screenshot 2024-08-20 112312](https://github.com/user-attachments/assets/eed08cce-c5e7-40f5-9214-46d7901e242d)
![Screenshot 2024-08-20 112320](https://github.com/user-attachments/assets/ba9c9663-72f9-4ba3-a109-9949a59e52bc)
![Screenshot 2024-08-20 112331](https://github.com/user-attachments/assets/15eaed49-b849-4323-b74f-b0234fcf4e59)
![Screenshot 2024-08-20 112341](https://github.com/user-attachments/assets/a00158e0-fc0e-4cb6-9175-dc37e3d1e9a5)
![Screenshot 2024-08-20 112410](https://github.com/user-attachments/assets/ca697216-56aa-477e-8ad4-41f8e1785f8a)
![Screenshot 2024-08-20 112422](https://github.com/user-attachments/assets/16c5aeb4-fdb6-4b70-9734-5fc453e7cf66)
![Screenshot 2024-08-20 112431](https://github.com/user-attachments/assets/becd02e4-3b94-4672-bd39-36b336ee557c)
![Screenshot 2024-08-20 112543](https://github.com/user-attachments/assets/30df51c2-0384-42ec-9945-78297f4c3ddf)
![Screenshot 2024-08-20 112557](https://github.com/user-attachments/assets/430587aa-e0cd-40b4-b8e4-f27d4aa80d9f)
![Screenshot 2024-08-20 112608](https://github.com/user-attachments/assets/9a59c7a9-b96e-474b-9a31-9db9310f505a)
![Screenshot 2024-08-20 112620](https://github.com/user-attachments/assets/e619dcd4-63bf-49df-9c7a-b24da7b6f39d)
![Screenshot 2024-08-20 112714](https://github.com/user-attachments/assets/3b5795f5-15af-4250-b6aa-d44a132bc785)

RESULT:

 Thus we have cleaned the data and removed the outliers by detection using IQR and Z-score method.



